<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Lane Graph Conditioning for Trajectory Prediction | Xingnan Zhou</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', sans-serif;
            line-height: 1.6;
            color: #333;
            background-color: #f5f6f8;
        }

        .header {
            background: linear-gradient(135deg, #0f1923 0%, #1a2940 50%, #243b55 100%);
            color: white;
            padding: 70px 20px 60px;
            text-align: center;
            position: relative;
            overflow: hidden;
        }

        .header::before {
            content: '';
            position: absolute;
            top: 0; left: 0; right: 0; bottom: 0;
            background: radial-gradient(ellipse at 30% 50%, rgba(78, 205, 196, 0.08) 0%, transparent 60%),
                        radial-gradient(ellipse at 70% 50%, rgba(69, 183, 209, 0.06) 0%, transparent 60%);
            pointer-events: none;
        }

        .header h1 {
            font-size: 2.4em; font-weight: 700; margin-bottom: 20px; line-height: 1.3;
            max-width: 950px; margin-left: auto; margin-right: auto; position: relative;
        }

        .header .authors { font-size: 1.15em; margin-top: 15px; opacity: 0.9; position: relative; }
        .header .venue { font-size: 1.05em; margin-top: 12px; opacity: 0.75; font-style: italic; position: relative; }

        .header-links {
            margin-top: 25px; display: flex; justify-content: center;
            gap: 16px; flex-wrap: wrap; position: relative;
        }

        .header-links a {
            display: inline-flex; align-items: center; gap: 6px; color: white; text-decoration: none;
            padding: 8px 20px; border: 1.5px solid rgba(255,255,255,0.35); border-radius: 6px;
            font-size: 0.95em; transition: all 0.2s ease;
        }

        .header-links a:hover { background: rgba(255,255,255,0.12); border-color: rgba(255,255,255,0.6); }

        .container { max-width: 960px; margin: 0 auto; padding: 40px 24px; }

        section {
            background: white; border-radius: 10px; padding: 36px 40px;
            margin-bottom: 28px; box-shadow: 0 1px 4px rgba(0,0,0,0.06);
        }

        h2 {
            font-size: 1.7em; color: #1a2940; margin-bottom: 20px;
            padding-bottom: 10px; border-bottom: 3px solid #4ECDC4;
        }

        h3 { font-size: 1.25em; color: #2d3e50; margin-top: 32px; margin-bottom: 14px; }
        p { margin-bottom: 14px; text-align: justify; line-height: 1.75; }

        .abstract {
            background-color: #f8f9fb; padding: 28px; border-left: 5px solid #4ECDC4;
            border-radius: 0 6px 6px 0; font-size: 1.02em; line-height: 1.85;
        }

        .highlight { background-color: #fff8e1; padding: 2px 5px; border-radius: 3px; }

        .findings-grid {
            display: grid; grid-template-columns: repeat(auto-fit, minmax(260px, 1fr));
            gap: 16px; margin: 24px 0;
        }

        .finding-card {
            background: #f8f9fb; border-radius: 8px; padding: 20px; border-left: 4px solid #4ECDC4;
        }

        .finding-card .number { font-size: 1.8em; font-weight: 700; color: #1a2940; line-height: 1; margin-bottom: 6px; }
        .finding-card .label { font-size: 0.88em; color: #666; line-height: 1.4; }

        .contributions {
            background-color: #f0f7ff; padding: 22px 28px; border-radius: 8px; margin: 22px 0;
        }

        .contributions ul { margin-left: 20px; margin-top: 10px; }
        .contributions li { margin-bottom: 10px; line-height: 1.65; }

        .table-wrapper { overflow-x: auto; margin: 20px 0; }

        table {
            width: 100%; border-collapse: collapse; font-size: 0.92em;
            border-radius: 8px; overflow: hidden; box-shadow: 0 1px 4px rgba(0,0,0,0.08);
        }

        table thead tr { background-color: #1a2940; color: white; }
        table th, table td { padding: 12px 14px; text-align: center; }
        table th:first-child, table td:first-child { text-align: left; }
        table tbody tr { border-bottom: 1px solid #e8e8e8; }
        table tbody tr:nth-of-type(even) { background-color: #fafbfc; }
        table tbody tr.best-result { background-color: #e6f7ef; font-weight: 600; }

        table caption {
            caption-side: top; text-align: left; font-size: 0.95em;
            font-weight: 600; color: #2d3e50; padding: 0 0 10px 0;
        }

        .figure { margin: 28px 0; text-align: center; }
        .figure img { max-width: 100%; border-radius: 8px; box-shadow: 0 2px 8px rgba(0,0,0,0.08); }

        .figure-caption {
            margin-top: 12px; font-size: 0.92em; color: #666; font-style: italic;
            text-align: center; max-width: 85%; margin-left: auto; margin-right: auto;
        }

        .gif-grid {
            display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px; margin: 28px 0;
        }

        .gif-item { text-align: center; }

        .gif-item img {
            width: 100%; border-radius: 8px; box-shadow: 0 3px 8px rgba(0,0,0,0.1);
            transition: transform 0.3s ease;
        }

        .gif-item img:hover { transform: scale(1.02); }
        .gif-item p { margin-top: 10px; font-size: 0.88em; color: #666; text-align: center; }

        .method-box { background-color: #f8f9fb; padding: 24px; border-radius: 8px; margin: 20px 0; }
        .method-component { margin-bottom: 18px; }
        .method-component:last-child { margin-bottom: 0; }
        .method-component h4 { color: #2a8c85; font-size: 1.05em; margin-bottom: 6px; }
        .method-component p { margin-bottom: 6px; }

        .note {
            background-color: #fffbef; border-left: 4px solid #e8a838;
            padding: 16px 20px; margin: 20px 0; border-radius: 0 6px 6px 0; font-size: 0.95em;
        }

        .note strong { color: #c08a20; }

        .insight {
            background-color: #f0f7ff; border-left: 4px solid #3b82f6;
            padding: 16px 20px; margin: 20px 0; border-radius: 0 6px 6px 0; font-size: 0.95em;
        }

        .insight strong { color: #2563eb; }

        .footer {
            background-color: #0f1923; color: white; text-align: center;
            padding: 30px 20px; margin-top: 20px;
        }

        .footer p { opacity: 0.75; text-align: center; font-size: 0.92em; }
        .footer a { color: #4ECDC4; text-decoration: none; }

        @media (max-width: 768px) {
            .header h1 { font-size: 1.6em; }
            section { padding: 24px 20px; }
            h2 { font-size: 1.4em; }
            .gif-grid { grid-template-columns: 1fr; }
            .findings-grid { grid-template-columns: 1fr; }
            table { font-size: 0.78em; }
            table th, table td { padding: 8px 6px; }
        }
    </style>
</head>
<body>
    <div class="header">
        <h1>Local Lane Graph Conditioning as a General Inductive Bias for Trajectory Prediction</h1>
        <div class="authors">Xingnan Zhou and Ciprian Alecsandru</div>
        <div class="venue">Concordia University, Montreal &middot; Submitted to MDPI Sustainability, 2026</div>
        <div class="header-links">
            <a href="assets/lane-conditioning-paper.pdf">Paper (PDF)</a>
            <a href="https://github.com/Jynxzzz/scenario-dreamer-jynxzzz">Code</a>
            <a href="#results">Results</a>
            <a href="#method">Method</a>
            <a href="#qualitative">Visualizations</a>
            <a href="index.html">Back to Portfolio</a>
        </div>
    </div>

    <div class="container">

        <!-- Abstract -->
        <section id="abstract">
            <h2>Abstract</h2>
            <div class="abstract">
                <p>
                    Accurate trajectory prediction for autonomous driving requires understanding both motion dynamics and road structure.
                    While recent learning-based approaches have shown promise, they often struggle to effectively incorporate structured
                    road information, leading to physically implausible predictions that violate lane constraints.
                </p>
                <p>
                    We present a <span class="highlight">structure-aware trajectory prediction framework</span> that explicitly conditions
                    on local lane graph structure. Our approach introduces a
                    <strong>"waterflow" algorithm</strong> that extracts a local lane graph via 3-hop breadth-first search from the ego
                    vehicle's current lane, reducing graph size by 80% while preserving critical connectivity information.
                    The extracted lane graph is encoded using graph message passing and fused
                    with trajectory features via cross-attention.
                </p>
                <p>
                    Evaluated on <strong>89,258 intersection scenarios</strong> from the Waymo Open Dataset, our approach achieves
                    <strong>up to 27.3% ADE improvement</strong> and <strong>42.7% miss rate reduction</strong> in multi-modal prediction.
                    The method is <strong>architecture-agnostic</strong>, demonstrating consistent gains on both LSTM (+18.7%) and
                    Transformer (+32.0%) backbones.
                    Error decomposition reveals balanced improvements across both longitudinal (+25.4%) and lateral (+26.5%) components,
                    with endpoint lateral error showing the strongest reduction (+30.5%).
                </p>
            </div>

            <div class="findings-grid">
                <div class="finding-card">
                    <div class="number">27.3%</div>
                    <div class="label">minADE improvement (8s, K=6 multi-modal)</div>
                </div>
                <div class="finding-card">
                    <div class="number">42.7%</div>
                    <div class="label">Miss Rate reduction (MR@5m: 33.9% to 19.4%)</div>
                </div>
                <div class="finding-card">
                    <div class="number">+47K</div>
                    <div class="label">Additional parameters for LSTM (+7.5% overhead)</div>
                </div>
                <div class="finding-card">
                    <div class="number">2 arch.</div>
                    <div class="label">Architecture-agnostic: LSTM and Transformer</div>
                </div>
            </div>

            <div class="contributions">
                <strong>Key Contributions:</strong>
                <ul>
                    <li><strong>Waterflow Local Lane Graph Extraction:</strong> Novel 3-hop BFS algorithm that identifies relevant road structure from the ego lane, achieving 80% graph size reduction while preserving connectivity</li>
                    <li><strong>Architecture-Agnostic Lane Conditioning:</strong> A graph-based lane encoding module with cross-attention fusion that integrates seamlessly into both LSTM and Transformer prediction backbones</li>
                    <li><strong>Comprehensive Evaluation:</strong> Large-scale experiments on 89K Waymo intersection scenes with multi-modal prediction, error decomposition, and cross-architecture validation</li>
                    <li><strong>Implicit Regularization Effect:</strong> We show that lane conditioning acts as an implicit regularizer for Transformer encoders, preventing the overfitting observed in unconditioned models</li>
                </ul>
            </div>
        </section>

        <!-- Main Results -->
        <section id="results">
            <h2>Experimental Results</h2>

            <p>
                We evaluate on <strong>89,258 intersection scenarios</strong> from the Waymo Open Dataset with train/val split.
                All models use the same data pipeline: 1.1s history (11 steps at 10Hz), neighbor encoding, and CV-residual prediction.
                The lane-conditioned (LC) models additionally receive the local lane graph extracted by the waterflow algorithm.
            </p>

            <h3>Short-Horizon Single-Modal Prediction (3s)</h3>
            <p>To establish statistical significance, we train 3 seeds for 3-second prediction and report mean and standard deviation.</p>

            <div class="table-wrapper">
                <table>
                    <caption>Table 1: 3s single-modal prediction (3 seeds, paired t-test p = 0.0071)</caption>
                    <thead>
                        <tr><th>Model</th><th>ADE@3s (mean &plusmn; std)</th><th>Improvement</th></tr>
                    </thead>
                    <tbody>
                        <tr><td>LSTM Baseline (BL)</td><td>0.559 &plusmn; 0.007</td><td>&mdash;</td></tr>
                        <tr class="best-result"><td>LSTM Lane-Cond (LC)</td><td><strong>0.507 &plusmn; 0.011</strong></td><td><strong>+9.3%</strong></td></tr>
                    </tbody>
                </table>
            </div>

            <h3>Long-Horizon Single-Modal Prediction (8s)</h3>
            <p>
                We extend the prediction horizon to 8 seconds (80 timesteps) and test both LSTM and Transformer backbones.
                Lane conditioning provides large improvements on both architectures, with Transformer benefiting even more (+32.0% ADE).
            </p>

            <div class="table-wrapper">
                <table>
                    <caption>Table 2: 8s single-modal prediction (seed42, 100 epochs)</caption>
                    <thead>
                        <tr><th>Model</th><th>ADE@8s</th><th>FDE@8s</th><th>ADE@3s</th><th>vs Baseline</th></tr>
                    </thead>
                    <tbody>
                        <tr><td>LSTM-BL</td><td>3.781</td><td>11.244</td><td>0.553</td><td>&mdash;</td></tr>
                        <tr class="best-result"><td>LSTM-LC</td><td><strong>3.075</strong></td><td><strong>8.688</strong></td><td>0.516</td><td><strong>+18.7%</strong></td></tr>
                        <tr style="border-top: 2.5px solid #ccc;"><td>TF-BL</td><td>4.859</td><td>13.875</td><td>0.828</td><td>&mdash;</td></tr>
                        <tr class="best-result"><td>TF-LC</td><td><strong>3.303</strong></td><td><strong>8.956</strong></td><td><strong>0.663</strong></td><td><strong>+32.0%</strong></td></tr>
                    </tbody>
                </table>
            </div>

            <div class="insight">
                <strong>Horizon Scaling:</strong> Lane conditioning benefit increases dramatically with prediction horizon:
                <strong>+9.3%</strong> at 3 seconds, <strong>+18.7%</strong> at 8 seconds (LSTM), and <strong>+32.0%</strong> at 8 seconds (Transformer).
                This confirms that structural road knowledge becomes increasingly critical for long-range prediction where constant-velocity assumptions break down.
            </div>

            <h3>Multi-Modal Prediction (8s, K=6)</h3>
            <p>For multi-modal prediction, each model generates K=6 trajectory hypotheses per agent. We use the winner-takes-all (WTA) training strategy and report min-of-6 metrics.</p>

            <div class="table-wrapper">
                <table>
                    <caption>Table 3: 8s multi-modal prediction K=6 (seed42, 100 epochs)</caption>
                    <thead>
                        <tr><th>Model</th><th>minADE</th><th>minFDE</th><th>MR@5m</th><th>vs Baseline</th></tr>
                    </thead>
                    <tbody>
                        <tr><td>LSTM-BL</td><td>1.839</td><td>4.959</td><td>33.9%</td><td>&mdash;</td></tr>
                        <tr class="best-result"><td>LSTM-LC</td><td><strong>1.337</strong></td><td><strong>3.289</strong></td><td><strong>19.4%</strong></td><td><strong>+27.3% / +33.7% / +42.7%</strong></td></tr>
                    </tbody>
                </table>
            </div>

            <div class="insight">
                <strong>Multi-Modal Gains:</strong> Lane conditioning reduces miss rate from 33.9% to 19.4% &mdash; a
                <strong>42.7% relative reduction</strong>. The multi-modal setting amplifies lane conditioning benefits
                (27.3% minADE improvement vs 18.7% single-modal) because lane structure helps the model
                generate trajectory hypotheses along distinct lane options (e.g., left turn vs straight).
            </div>

            <h3>Context: Comparison with Waymo Official Baselines</h3>
            <p>
                While not a direct apples-to-apples comparison (different features, evaluation splits), the Waymo Motion
                Prediction Challenge provides useful context for our results.
            </p>

            <div class="table-wrapper">
                <table>
                    <caption>Table 4: Context comparison with Waymo official baselines (minADE, 8s, K=6)</caption>
                    <thead>
                        <tr><th>Model</th><th>Features</th><th>minADE (m)</th></tr>
                    </thead>
                    <tbody>
                        <tr><td>Waymo LSTM (bare)&dagger;</td><td>Agent state (pos, vel, bbox)</td><td>2.63</td></tr>
                        <tr><td>Our LSTM-BL</td><td>Position + Neighbor</td><td>1.84</td></tr>
                        <tr><td>Waymo LSTM + rg + ts + hi&dagger;</td><td>Agent state + map + signals + interactions</td><td>1.34</td></tr>
                        <tr class="best-result"><td>Our LSTM-LC</td><td>Position + Neighbor + Lane</td><td><strong>1.34</strong></td></tr>
                    </tbody>
                </table>
            </div>

            <div class="note">
                <strong>Note:</strong> Our LC-LSTM with only position + lane features <strong>matches the Waymo official
                full-feature LSTM</strong> (minADE = 1.34m), demonstrating that local lane graph conditioning can
                effectively substitute for hand-engineered kinematic features. &dagger;Waymo baselines from
                Ettinger et al. (2021), Table 2 (vehicle class, standard val set).
            </div>
        </section>

        <!-- Error Decomposition -->
        <section id="error-decomp">
            <h2>Error Decomposition Analysis</h2>

            <p>
                To understand <em>where</em> lane conditioning provides its benefits, we decompose prediction error into
                longitudinal (along-lane direction) and lateral (cross-lane direction) components for both average and endpoint errors.
            </p>

            <div class="table-wrapper">
                <table>
                    <caption>Table 5: Error decomposition (8s, K=6 multi-modal)</caption>
                    <thead>
                        <tr><th>Component</th><th>Baseline (m)</th><th>Lane-Cond (m)</th><th>Improvement</th></tr>
                    </thead>
                    <tbody>
                        <tr><td>Average Longitudinal</td><td>1.238</td><td>0.924</td><td>+25.4%</td></tr>
                        <tr><td>Average Lateral</td><td>0.919</td><td>0.675</td><td>+26.5%</td></tr>
                        <tr><td>Endpoint Longitudinal</td><td>3.561</td><td>2.577</td><td>+27.6%</td></tr>
                        <tr class="best-result"><td>Endpoint Lateral</td><td>2.687</td><td>1.867</td><td><strong>+30.5%</strong></td></tr>
                    </tbody>
                </table>
            </div>

            <div class="figure">
                <img src="assets/error_decomposition_timeline.png" alt="Error Decomposition Over Time">
                <div class="figure-caption">
                    Figure 1: Error decomposition over the prediction horizon. Lane conditioning reduces both longitudinal and
                    lateral components, with the strongest gains at longer horizons where lane structure matters most.
                </div>
            </div>

            <div class="figure">
                <img src="assets/error_decomposition_improvement.png" alt="Error Decomposition Improvement">
                <div class="figure-caption">
                    Figure 2: Improvement breakdown by error component. Endpoint lateral error shows the largest
                    improvement (+30.5%), confirming that lane conditioning helps maintain correct lane assignment over long horizons.
                </div>
            </div>

            <div class="insight">
                <strong>Analysis:</strong> Lane conditioning provides <strong>balanced improvements</strong> across both error axes,
                contrary to our initial hypothesis that it would primarily reduce lateral (cross-lane) error.
                The strongest individual gain is on <strong>endpoint lateral error (+30.5%)</strong>, which aligns with the intuition
                that lane structure is most critical for determining the final lane assignment at the end of the 8-second horizon.
                The substantial longitudinal improvement (+25.4%/+27.6%) suggests that lane geometry also informs speed profile estimation.
            </div>
        </section>

        <!-- Method Overview -->
        <section id="method">
            <h2>Method Overview</h2>

            <p>
                Our framework adds a lane conditioning module to a standard trajectory prediction pipeline.
                The key design principle is <strong>architecture-agnostic fusion</strong>: the lane encoder communicates
                with the trajectory encoder through cross-attention, making it compatible with any backbone.
            </p>

            <div class="figure">
                <img src="assets/architecture.svg" alt="Model Architecture" style="max-width: 100%; height: auto;">
                <div class="figure-caption">
                    Figure 3: Model architecture overview. Lane features and adjacency matrix are processed through graph message
                    passing, then fused with the trajectory encoding via cross-attention.
                </div>
            </div>

            <div class="method-box">
                <div class="method-component">
                    <h4>1. Trajectory Encoder (LSTM / Transformer)</h4>
                    <p>
                        Encodes the observed trajectory history (1.1 seconds, 11 timesteps at 10Hz).
                        <strong>LSTM variant:</strong> compresses history into a single hidden vector (B, 128).
                        <strong>Transformer variant:</strong> 2-layer, 4-head self-attention with learnable positional embeddings.
                    </p>
                </div>

                <div class="method-component">
                    <h4>2. Lane Graph Encoder (MLP + Message Passing + Cross-Attention)</h4>
                    <p>
                        <strong>Lane Feature Extraction:</strong> Each lane segment is encoded using an MLP that processes
                        polyline points, traffic light states, and lane types.
                    </p>
                    <p>
                        <strong>Graph Message Passing:</strong> 2 rounds of message passing propagate information through
                        lane connectivity (predecessors, successors, left/right neighbors).
                    </p>
                    <p>
                        <strong>Cross-Attention Fusion:</strong> Lane embeddings attend to trajectory features to select
                        the most relevant structural context for the current motion.
                    </p>
                </div>

                <div class="method-component">
                    <h4>3. Neighbor Encoder (LSTM + Max-Pool)</h4>
                    <p>
                        Encodes surrounding vehicles' trajectories using per-neighbor LSTMs, then aggregates via max-pooling
                        to create a permutation-invariant neighbor representation.
                    </p>
                </div>

                <div class="method-component">
                    <h4>4. Fusion + MLP Decoder with CV-Residual Prediction</h4>
                    <p>
                        Fuses trajectory, lane, and neighbor embeddings through concatenation followed by MLP layers.
                        The decoder predicts residuals relative to a constant velocity baseline. For multi-modal prediction,
                        K=6 heads generate diverse trajectory hypotheses trained with winner-takes-all loss.
                    </p>
                </div>
            </div>

            <div class="note">
                <strong>Parameter Overhead:</strong> The lane conditioning module adds only <strong>+47K parameters (+7.5%)</strong>
                for LSTM and <strong>+152K parameters (+33.3%)</strong> for Transformer backbones.
            </div>
        </section>

        <!-- Waterflow -->
        <section id="waterflow">
            <h2>Waterflow Local Lane Graph Extraction</h2>

            <p>
                A key challenge in lane-conditioned prediction is managing the complexity of full road graphs.
                Real-world intersections can contain dozens of lane segments, most of which are irrelevant to
                the ego vehicle's near-future trajectory.
            </p>

            <div class="figure">
                <img src="assets/fig_waterflow_concept.png" alt="Waterflow Concept">
                <div class="figure-caption">
                    Figure 4: Waterflow algorithm concept. Starting from the ego lane (red), we perform 3-hop BFS exploration
                    along lane connectivity to extract a local subgraph, reducing graph size by approximately 80%.
                </div>
            </div>

            <div class="figure">
                <img src="assets/fig_graph_topology.png" alt="Graph Topology">
                <div class="figure-caption">
                    Figure 5: Extracted lane graph topology showing lane segments (nodes) and their connectivity relationships
                    (edges). The graph captures turn options, lane merges, and intersection structure.
                </div>
            </div>
        </section>

        <!-- Key Findings -->
        <section id="ablation">
            <h2>Key Findings</h2>

            <h3>1. Benefit Increases with Prediction Horizon</h3>
            <p>
                Lane conditioning becomes increasingly valuable as the prediction horizon grows.
                At 3 seconds, constant-velocity extrapolation is a reasonable approximation.
                At 8 seconds, vehicles may change lanes, turn at intersections, or follow curved roads.
            </p>
            <div class="table-wrapper">
                <table>
                    <thead><tr><th>Horizon</th><th>Setting</th><th>Improvement (ADE)</th></tr></thead>
                    <tbody>
                        <tr><td>3s</td><td>Single-modal, LSTM</td><td>+9.3%</td></tr>
                        <tr><td>8s</td><td>Single-modal, LSTM</td><td>+18.7%</td></tr>
                        <tr class="best-result"><td>8s</td><td>Multi-modal K=6, LSTM</td><td><strong>+27.3%</strong></td></tr>
                    </tbody>
                </table>
            </div>

            <h3>2. Architecture-Agnostic: LSTM and Transformer</h3>
            <p>
                Both LSTM and Transformer encoders benefit substantially, with Transformer showing an even larger relative gain
                (+32.0% vs +18.7%). Lane conditioning acts as an <strong>implicit regularizer</strong> for the Transformer &mdash;
                TF-BL overfits severely (ADE 4.859), while TF-LC achieves ADE 3.303.
            </p>

            <h3>3. Balanced Error Reduction</h3>
            <p>
                Error decomposition reveals improvements in <em>both</em> longitudinal and lateral prediction.
                The strongest gain is on endpoint lateral error (+30.5%).
            </p>

            <h3>4. Delayed Convergence, Lower Asymptote</h3>
            <p>
                The lane-conditioned model converges more slowly than the baseline (optimum around epoch 94
                vs epoch 23 for baseline). Short training runs can be <strong>misleading</strong> &mdash;
                100 epochs is essential to observe the full benefit.
            </p>

            <div class="figure">
                <img src="assets/error_over_horizon_v4.png" alt="Error Over Horizon">
                <div class="figure-caption">
                    Figure 6: Prediction error growth over the horizon. Lane conditioning achieves consistently
                    lower error, with the gap widening at longer horizons.
                </div>
            </div>

            <h3>5. Matching Waymo Official with Minimal Features</h3>
            <p>
                Our LC-LSTM achieves minADE = 1.34m using only <strong>position + lane features</strong>, matching the
                Waymo official LSTM baseline that uses the full feature set (velocity, heading, object type, etc.).
            </p>
        </section>

        <!-- Qualitative Results -->
        <section id="qualitative">
            <h2>Qualitative Results</h2>

            <p>
                We visualize predictions on diverse intersection scenarios. The lane-conditioned model successfully
                captures lane-following behavior and produces physically plausible trajectories that respect road structure.
            </p>

            <div class="gif-grid">
                <div class="gif-item">
                    <img src="assets/anim_scene_0_straight.gif" alt="Straight-through scenario">
                    <p>Straight-through at intersection<br><strong>BL: 4.35m &rarr; LC: 1.19m (+73%)</strong></p>
                </div>
                <div class="gif-item">
                    <img src="assets/anim_scene_1_left_turn.gif" alt="Left turn scenario">
                    <p>Left turn at complex intersection<br><strong>BL: 8.95m &rarr; LC: 3.09m (+65%)</strong></p>
                </div>
                <div class="gif-item">
                    <img src="assets/anim_scene_2_left_turn.gif" alt="Left turn scenario 2">
                    <p>Left turn with lane following<br><strong>BL: 3.64m &rarr; LC: 1.38m (+62%)</strong></p>
                </div>
            </div>

            <div class="gif-grid">
                <div class="gif-item">
                    <img src="assets/anim_scene_3_straight.gif" alt="Straight scenario 2">
                    <p>Straight-through with neighbors<br><strong>BL: 1.33m &rarr; LC: 0.54m (+59%)</strong></p>
                </div>
                <div class="gif-item">
                    <img src="assets/anim_scene_4_curve.gif" alt="Curved lane scenario">
                    <p>Curved lane following<br><strong>BL: 1.89m &rarr; LC: 0.83m (+56%)</strong></p>
                </div>
            </div>

            <div class="figure-caption" style="margin-top: 16px;">
                Side-by-side animated comparison: LSTM Baseline (left) vs LSTM + Lane Conditioning (right).
                K=6 multi-modal predictions grow step-by-step over the 8-second horizon.
            </div>
        </section>

        <!-- Rolling Prediction Demos -->
        <section id="rolling">
            <h2>Rolling Prediction</h2>

            <p>
                We visualize how predictions evolve as the ego vehicle drives through a full 9.1-second scenario.
                At each time step, the model generates K=6 multi-modal predictions for the next 8 seconds.
            </p>

            <div class="gif-grid">
                <div class="gif-item">
                    <img src="assets/rolling_demo_0_straight.gif" alt="Rolling prediction - straight">
                    <p>Straight-through (full scenario)<br><strong>Avg minADE: BL 2.82m &rarr; LC 1.21m (+57%)</strong></p>
                </div>
                <div class="gif-item">
                    <img src="assets/rolling_demo_1_turn.gif" alt="Rolling prediction - turn">
                    <p>Turn maneuver (full scenario)<br><strong>Avg minADE: BL 3.70m &rarr; LC 1.66m (+55%)</strong></p>
                </div>
                <div class="gif-item">
                    <img src="assets/rolling_demo_2_straight.gif" alt="Rolling prediction - straight 2">
                    <p>Straight with lane guidance<br><strong>Avg minADE: BL 1.03m &rarr; LC 0.59m (+43%)</strong></p>
                </div>
            </div>
        </section>

        <!-- Additional Figures -->
        <section id="figures">
            <h2>Additional Analysis</h2>

            <h3>Scene Difficulty Analysis</h3>
            <div class="figure">
                <img src="assets/difficulty_binned_analysis.png" alt="Difficulty Analysis">
                <div class="figure-caption">
                    Figure 7: Lane conditioning improvement by scene difficulty. The benefit is most pronounced on challenging scenarios.
                </div>
            </div>

            <div class="figure">
                <img src="assets/per_scene_head_to_head.png" alt="Per-Scene Head-to-Head">
                <div class="figure-caption">
                    Figure 8: Per-scene head-to-head comparison. Points below the diagonal indicate scenes
                    where lane conditioning outperforms the baseline.
                </div>
            </div>
        </section>
    </div>

    <div class="footer">
        <p>Xingnan Zhou &middot; Concordia University, Montreal &middot; <a href="index.html">Portfolio</a></p>
        <p style="margin-top: 8px;">&copy; 2026 | Built with the <a href="https://github.com/ss-zheng/Scenario-Dreamer">Scenario Dreamer</a> framework</p>
    </div>
</body>
</html>
