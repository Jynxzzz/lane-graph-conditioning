<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Lane Graph Conditioning for Trajectory Prediction | Xingnan Zhou</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', sans-serif;
            line-height: 1.6;
            color: #333;
            background-color: #f8f9fa;
        }

        .header {
            background: linear-gradient(135deg, #1a1a2e 0%, #2d2d44 100%);
            color: white;
            padding: 60px 20px;
            text-align: center;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }

        .header h1 {
            font-size: 2.5em;
            font-weight: 700;
            margin-bottom: 20px;
            line-height: 1.3;
            max-width: 1000px;
            margin-left: auto;
            margin-right: auto;
        }

        .header .authors {
            font-size: 1.2em;
            margin-top: 15px;
            opacity: 0.9;
        }

        .header .venue {
            font-size: 1.1em;
            margin-top: 10px;
            opacity: 0.8;
            font-style: italic;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 40px 20px;
            background-color: white;
            box-shadow: 0 0 20px rgba(0, 0, 0, 0.05);
        }

        section {
            margin-bottom: 50px;
        }

        h2 {
            font-size: 2em;
            color: #1a1a2e;
            margin-bottom: 20px;
            padding-bottom: 10px;
            border-bottom: 3px solid #4ECDC4;
        }

        h3 {
            font-size: 1.5em;
            color: #2d2d44;
            margin-top: 30px;
            margin-bottom: 15px;
        }

        p {
            margin-bottom: 15px;
            text-align: justify;
        }

        .abstract {
            background-color: #f8f9fa;
            padding: 30px;
            border-left: 5px solid #4ECDC4;
            border-radius: 5px;
            font-size: 1.05em;
            line-height: 1.8;
        }

        .highlight {
            background-color: #fff9e6;
            padding: 3px 6px;
            border-radius: 3px;
        }

        .contributions {
            background-color: #f0f8ff;
            padding: 20px;
            border-radius: 5px;
            margin: 20px 0;
        }

        .contributions ul {
            margin-left: 20px;
            margin-top: 10px;
        }

        .contributions li {
            margin-bottom: 10px;
            line-height: 1.6;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin: 25px 0;
            font-size: 0.95em;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.1);
        }

        table thead tr {
            background-color: #1a1a2e;
            color: white;
            text-align: left;
        }

        table th,
        table td {
            padding: 14px 12px;
            text-align: center;
        }

        table th:first-child,
        table td:first-child {
            text-align: left;
        }

        table tbody tr {
            border-bottom: 1px solid #dddddd;
        }

        table tbody tr:nth-of-type(even) {
            background-color: #f8f9fa;
        }

        table tbody tr:last-of-type {
            border-bottom: 2px solid #1a1a2e;
        }

        table tbody tr.best-result {
            background-color: #e8f5e9;
            font-weight: 600;
        }

        .gif-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin: 30px 0;
        }

        .gif-item {
            text-align: center;
        }

        .gif-item img {
            width: 100%;
            border-radius: 8px;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
            transition: transform 0.3s ease;
        }

        .gif-item img:hover {
            transform: scale(1.02);
        }

        .gif-item p {
            margin-top: 10px;
            font-size: 0.9em;
            color: #666;
            text-align: center;
        }

        .figure {
            margin: 30px 0;
            text-align: center;
        }

        .figure img {
            max-width: 100%;
            border-radius: 8px;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        }

        .figure-caption {
            margin-top: 15px;
            font-size: 0.95em;
            color: #666;
            font-style: italic;
            text-align: center;
        }

        .method-box {
            background-color: #f8f9fa;
            padding: 25px;
            border-radius: 8px;
            margin: 20px 0;
        }

        .method-component {
            margin-bottom: 20px;
        }

        .method-component h4 {
            color: #4ECDC4;
            font-size: 1.1em;
            margin-bottom: 8px;
        }

        .method-component p {
            margin-bottom: 8px;
        }

        .note {
            background-color: #fff9e6;
            border-left: 4px solid #FF6B6B;
            padding: 15px;
            margin: 20px 0;
            border-radius: 4px;
        }

        .note strong {
            color: #FF6B6B;
        }

        .footer {
            background-color: #1a1a2e;
            color: white;
            text-align: center;
            padding: 30px 20px;
            margin-top: 50px;
        }

        .footer p {
            opacity: 0.8;
            text-align: center;
        }

        .badge {
            display: inline-block;
            background-color: #45B7D1;
            color: white;
            padding: 5px 12px;
            border-radius: 15px;
            font-size: 0.85em;
            margin-right: 8px;
            font-weight: 600;
        }

        @media (max-width: 768px) {
            .header h1 {
                font-size: 1.8em;
            }

            h2 {
                font-size: 1.5em;
            }

            .gif-grid {
                grid-template-columns: 1fr;
            }

            table {
                font-size: 0.8em;
            }

            table th,
            table td {
                padding: 8px 6px;
            }
        }
    </style>
</head>
<body>
    <div class="header">
        <h1>Local Lane Graph Conditioning as a General Inductive Bias for Trajectory Prediction</h1>
        <div class="authors">Xingnan Zhou and Ciprian Alecsandru</div>
        <div class="venue">Concordia University, Montreal &middot; Submitted to MDPI Sustainability, 2026</div>
        <div style="margin-top: 20px; display: flex; justify-content: center; gap: 14px; flex-wrap: wrap;">
            <a href="assets/lane-conditioning-paper.pdf" style="color: white; text-decoration: none; padding: 8px 18px; border: 1.5px solid rgba(255,255,255,0.35); border-radius: 6px; font-size: 0.93em;">Paper (PDF)</a>
            <a href="https://github.com/Jynxzzz/scenario-dreamer-jynxzzz" style="color: white; text-decoration: none; padding: 8px 18px; border: 1.5px solid rgba(255,255,255,0.35); border-radius: 6px; font-size: 0.93em;">Code</a>
            <a href="index.html" style="color: white; text-decoration: none; padding: 8px 18px; border: 1.5px solid rgba(255,255,255,0.35); border-radius: 6px; font-size: 0.93em;">Back to Portfolio</a>
        </div>
    </div>

    <div class="container">
        <!-- Abstract -->
        <section id="abstract">
            <h2>Abstract</h2>
            <div class="abstract">
                <p>
                    Accurate trajectory prediction for autonomous driving requires a deep understanding of road structure and topology.
                    While recent learning-based approaches have shown promise, they often struggle to effectively incorporate structured
                    road information, leading to physically implausible predictions that violate lane constraints.
                </p>
                <p>
                    We present a <span class="highlight">structure-aware trajectory prediction framework</span> that explicitly conditions
                    on local lane graph structure. Our key insight is that not all road structure is equally relevant—we introduce a
                    <strong>"waterflow" algorithm</strong> that extracts a local lane graph via 3-hop breadth-first search from the ego
                    vehicle's current lane, reducing graph size by 80% while preserving critical connectivity information.
                </p>
                <p>
                    The extracted lane graph is encoded using graph message passing to capture lane connectivity patterns, then fused
                    with trajectory history via cross-attention. An LSTM decoder conditioned on this structured representation generates
                    physically plausible future trajectories. We further enhance learning through dual supervision with an auxiliary
                    structure prediction head.
                </p>
                <p>
                    Evaluated on challenging Waymo Open Dataset intersection scenarios, our approach achieves consistent improvements
                    over LSTM baselines. Error decomposition reveals that lane conditioning primarily reduces cross-lane
                    (lateral) error, confirming that the model learns to use lane structure for correct lane assignment.
                    Benefits are strongest on challenging scenarios with only a modest parameter increase.
                </p>
            </div>

            <div class="contributions">
                <strong>Key Contributions:</strong>
                <ul>
                    <li><strong>Waterflow Local Lane Graph Extraction:</strong> Novel 3-hop BFS algorithm that identifies relevant road structure from ego lane, achieving 80% graph size reduction</li>
                    <li><strong>Graph Message Passing for Lane Connectivity:</strong> Graph neural network that encodes lane relationships and topology through message passing</li>
                    <li><strong>Dual Supervision Framework:</strong> Auxiliary structure prediction head that guides the model to learn richer lane representations</li>
                    <li><strong>Empirical Validation:</strong> Comprehensive evaluation on Waymo intersection scenarios demonstrating consistent improvements across multiple metrics</li>
                </ul>
            </div>
        </section>

        <!-- Method Overview -->
        <section id="method">
            <h2>Method Overview</h2>

            <p>
                Our trajectory prediction framework consists of four main components that work together to generate
                structure-aware predictions:
            </p>

            <div class="method-box">
                <div class="method-component">
                    <h4>1. Trajectory Encoder (LSTM)</h4>
                    <p>
                        Encodes the observed trajectory history (1.1 seconds, 11 timesteps at 10Hz) into a fixed-length
                        representation. The LSTM processes temporal dynamics and extracts motion patterns from historical positions.
                    </p>
                </div>

                <div class="method-component">
                    <h4>2. Lane Graph Encoder (MLP + Message Passing + Cross-Attention)</h4>
                    <p>
                        <strong>Lane Feature Extraction:</strong> Each lane segment is encoded using an MLP that processes
                        polyline points, traffic light states, and lane types (vehicle/bike/pedestrian).
                    </p>
                    <p>
                        <strong>Graph Message Passing:</strong> Multiple rounds of message passing propagate information through
                        lane connectivity. Each node aggregates information from connected lanes (predecessors, successors, left/right neighbors)
                        to build a relational understanding of road structure.
                    </p>
                    <p>
                        <strong>Cross-Attention Fusion:</strong> Lane embeddings attend to trajectory features to select
                        relevant structural context. This attention mechanism allows the model to focus on lanes that matter
                        most for the current trajectory.
                    </p>
                </div>

                <div class="method-component">
                    <h4>3. Neighbor Encoder (LSTM + Max-Pool)</h4>
                    <p>
                        Encodes surrounding vehicles' trajectories using per-neighbor LSTMs, then aggregates via max-pooling
                        to create a permutation-invariant neighbor representation capturing social context.
                    </p>
                </div>

                <div class="method-component">
                    <h4>4. Fusion + MLP Decoder with CV-Residual Prediction</h4>
                    <p>
                        Fuses trajectory, lane, and neighbor embeddings through concatenation followed by MLP layers.
                        The decoder predicts residuals relative to constant velocity baseline at each future timestep
                        (3 seconds, 30 timesteps at 10Hz). This residual formulation provides a strong inductive bias
                        and stabilizes training.
                    </p>
                </div>
            </div>

            <div class="note">
                <strong>Note:</strong> The dual supervision variant adds an auxiliary prediction head that predicts
                which lanes the vehicle will traverse. This provides additional supervision signal during training,
                encouraging the model to learn richer lane representations.
            </div>

            <div style="text-align: center; margin: 30px 0;">
                <img src="assets/architecture.svg" alt="Model Architecture" style="max-width: 100%; height: auto;">
                <p class="caption">Model architecture overview. Lane features and adjacency matrix are processed through graph message passing before cross-attention fusion with the ego trajectory encoding.</p>
            </div>
        </section>

        <!-- Waterflow Graph Visualization -->
        <section id="waterflow">
            <h2>Waterflow Local Lane Graph Extraction</h2>

            <p>
                A key challenge in lane-conditioned prediction is managing the complexity of full road graphs.
                Our waterflow algorithm efficiently extracts a local subgraph centered on the ego vehicle's current lane:
            </p>

            <div class="figure">
                <img src="assets/fig_waterflow_concept.png" alt="Waterflow Concept">
                <div class="figure-caption">
                    Figure 1: Waterflow algorithm concept. Starting from the ego lane (red), we perform 3-hop BFS exploration
                    along lane connectivity to extract a local subgraph. This captures relevant road structure while reducing
                    computational complexity by 80%.
                </div>
            </div>

            <div class="figure">
                <img src="assets/fig_graph_topology.png" alt="Graph Topology">
                <div class="figure-caption">
                    Figure 2: Extracted lane graph topology showing lane segments (nodes) and their connectivity relationships
                    (edges). The graph captures turn options, lane merges, and intersection structure critical for prediction.
                </div>
            </div>

            <p style="margin-top: 25px;">
                The 3-hop BFS ensures we capture lanes the vehicle might reach within the prediction horizon while
                discarding irrelevant road structure. This local extraction is both computationally efficient and
                semantically meaningful.
            </p>
        </section>

        <!-- Results Table -->
        <section id="results">
            <h2>Quantitative Results</h2>

            <p>
                We evaluate on 50 challenging intersection scenarios from the Waymo Open Dataset. Metrics include
                Average Displacement Error (ADE) and Final Displacement Error (FDE) at 1s, 2s, and 3s horizons.
            </p>

            <table>
                <thead>
                    <tr>
                        <th>Method</th>
                        <th>Params</th>
                        <th>ADE@1s ↓</th>
                        <th>FDE@1s ↓</th>
                        <th>ADE@2s ↓</th>
                        <th>FDE@2s ↓</th>
                        <th>ADE@3s ↓</th>
                        <th>FDE@3s ↓</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>Constant Velocity</td>
                        <td>—</td>
                        <td>0.246</td>
                        <td>0.494</td>
                        <td>0.597</td>
                        <td>1.377</td>
                        <td>1.108</td>
                        <td>2.929</td>
                    </tr>
                    <tr>
                        <td>LSTM Baseline</td>
                        <td>396K</td>
                        <td>0.150</td>
                        <td>0.352</td>
                        <td>0.487</td>
                        <td>1.303</td>
                        <td>1.035</td>
                        <td>2.905</td>
                    </tr>
                    <tr class="best-result">
                        <td>Lane-Conditioned</td>
                        <td>443K</td>
                        <td>0.162</td>
                        <td>0.354</td>
                        <td>0.483</td>
                        <td>1.266</td>
                        <td><strong>1.011</strong></td>
                        <td><strong>2.835</strong></td>
                    </tr>
                    <tr>
                        <td>Dual Supervised</td>
                        <td>521K</td>
                        <td>0.153</td>
                        <td>0.368</td>
                        <td>0.505</td>
                        <td>1.347</td>
                        <td>1.065</td>
                        <td>2.970</td>
                    </tr>
                </tbody>
            </table>

            <div class="note">
                <strong>V4 Results (5-seed average).</strong> Compared to V3, data expansion (6x) and rotation
                augmentation reduce baseline ADE@3s by 5.6%. Lane conditioning further reduces ADE@3s by 2.3%
                and FDE@3s by 2.4% (p=0.094, marginal significance). Improvement is strongest on challenging
                scenarios (up to 6% on hard val sets).
            </div>

            <p style="margin-top: 25px;">
                The lane-conditioned model achieves the best ADE@3s (1.011m) and FDE@3s (2.835m), outperforming
                both the baseline and the dual supervised variant. The lane conditioning module adds only
                16.5K parameters (+4.2%) while providing consistent improvements at longer prediction horizons
                where road structure becomes most critical.
            </p>
        </section>

        <!-- Qualitative Results -->
        <section id="qualitative">
            <h2>Qualitative Results</h2>

            <p>
                We visualize predictions on diverse intersection scenarios including left turns, right turns, and
                straight-through maneuvers. The model successfully captures lane-following behavior and produces
                physically plausible trajectories.
            </p>

            <div class="gif-grid">
                <div class="gif-item">
                    <img src="assets/anim_scene_0_turning.gif" alt="Scene 0 - Turning">
                    <p>Scene 0: Left turn at intersection</p>
                </div>
                <div class="gif-item">
                    <img src="assets/anim_scene_2_turning.gif" alt="Scene 2 - Turning">
                    <p>Scene 2: Right turn maneuver</p>
                </div>
                <div class="gif-item">
                    <img src="assets/anim_scene_4_straight.gif" alt="Scene 4 - Straight">
                    <p>Scene 4: Straight-through crossing</p>
                </div>
            </div>

            <div class="figure-caption" style="margin-top: 20px;">
                Animated BEV predictions showing history trajectory (white), ground truth future (green),
                and model predictions. The model successfully follows lane structure and produces smooth,
                realistic trajectories across different maneuver types.
            </div>
        </section>

        <!-- Ablation Study -->
        <section id="ablation">
            <h2>Ablation Studies</h2>

            <h3>V4: Enhanced Model with Graph Message Passing</h3>
            <p>
                Our V4 architecture incorporates 2-layer graph message passing on the lane adjacency matrix,
                6x dataset expansion via anchor frame enumeration, and full rotation augmentation.
                These improvements yield significant gains over the V3 baseline.
            </p>

            <div class="figure">
                <img src="assets/v3_vs_v4_comparison.png" alt="V3 vs V4 Comparison">
                <div class="figure-caption">
                    Figure 3: V3 vs V4 architecture comparison. The V4 improvements (graph message passing,
                    data expansion, rotation augmentation) reduce ADE@3s by 5-10% across all model variants.
                </div>
            </div>

            <h3>Model Component Comparison (V4)</h3>
            <div class="figure">
                <img src="assets/main_comparison_v4.png" alt="V4 Main Comparison">
                <div class="figure-caption">
                    Figure 4: V4 comparison across prediction horizons. Lane-conditioned and dual supervised
                    models consistently outperform the LSTM baseline, with benefits increasing at longer horizons.
                </div>
            </div>

            <h3>Error Evolution Over Prediction Horizon</h3>
            <div class="figure">
                <img src="assets/error_over_horizon_v4.png" alt="V4 Error Over Horizon">
                <div class="figure-caption">
                    Figure 5: V4 prediction error growth over the 3-second horizon. All learned models
                    substantially outperform the constant velocity baseline, with lane-conditioned variants
                    achieving the lowest error at longer horizons.
                </div>
            </div>

            <h3>Error Decomposition: Along-Lane vs Cross-Lane</h3>
            <p>
                We decompose prediction error into longitudinal (along-lane) and lateral (cross-lane) components
                to understand <em>where</em> lane conditioning provides its benefits.
            </p>
            <div class="figure">
                <img src="assets/error_decomposition_timeline.png" alt="Error Decomposition">
                <div class="figure-caption">
                    Figure 6: Error decomposition over time. Lane conditioning primarily reduces cross-lane
                    (lateral) error — confirming that lane graph structure helps keep predictions on the
                    correct lane, while longitudinal error (speed estimation) dominates overall.
                </div>
            </div>
            <div class="figure">
                <img src="assets/error_decomposition_improvement.png" alt="Error Decomposition Improvement">
                <div class="figure-caption">
                    Figure 7: Lane conditioning improvement decomposition. Cross-lane improvement is consistently
                    larger than along-lane improvement, validating that lane graph conditioning addresses
                    lateral positioning errors.
                </div>
            </div>

            <h3>Scene Difficulty Analysis</h3>
            <p>
                We analyze whether lane conditioning benefits vary by scene difficulty. Scenes are binned
                into easy, medium, and hard categories based on baseline ADE.
            </p>
            <div class="figure">
                <img src="assets/difficulty_binned_analysis.png" alt="Difficulty Analysis">
                <div class="figure-caption">
                    Figure 8: Lane conditioning improvement by scene difficulty. The benefit of lane structure
                    is most pronounced on challenging scenarios where the baseline struggles.
                </div>
            </div>
            <div class="figure">
                <img src="assets/per_scene_head_to_head.png" alt="Per-Scene Head-to-Head">
                <div class="figure-caption">
                    Figure 9: Per-scene head-to-head comparison. Points below the diagonal indicate scenes
                    where lane conditioning outperforms the baseline. Color indicates trajectory curvature.
                </div>
            </div>

            <h3>LSTM vs MLP Decoder Comparison</h3>
            <div class="figure">
                <img src="assets/decoder_comparison_v2_v3.png" alt="Decoder Comparison">
                <div class="figure-caption">
                    Figure 10: Comparison of LSTM decoder (V2) vs MLP decoder (V3). The MLP decoder with
                    CV-residual prediction achieves comparable performance with significantly fewer parameters
                    and faster inference.
                </div>
            </div>

            <h3>Per-Seed Consistency</h3>
            <div class="figure">
                <img src="assets/per_seed_consistency_v4.png" alt="Per-Seed Consistency">
                <div class="figure-caption">
                    Figure 11: V4 per-seed consistency across 5 random seeds. Lane-conditioned models
                    consistently match or outperform the baseline across all seeds, demonstrating
                    robust improvement.
                </div>
            </div>

            <p style="margin-top: 25px;">
                Our comprehensive ablation studies demonstrate that: (1) graph message passing on lane adjacency
                captures topological relationships for better predictions, (2) lane conditioning primarily reduces
                cross-lane (lateral) error, confirming it helps with lane assignment, (3) benefits are strongest
                on challenging scenarios, and (4) the MLP decoder with CV-residual prediction provides an efficient
                architecture.
            </p>
        </section>

        <!-- Additional Visualizations -->
        <section id="visualizations">
            <h2>Additional Visualizations</h2>

            <div class="gif-grid">
                <div class="gif-item">
                    <img src="assets/anim_scene_1_straight.gif" alt="Scene 1">
                    <p>Scene 1: Complex intersection crossing</p>
                </div>
                <div class="gif-item">
                    <img src="assets/anim_scene_3_turning.gif" alt="Scene 3">
                    <p>Scene 3: Multi-lane turn scenario</p>
                </div>
            </div>
        </section>
    </div>

    <div class="footer">
        <p>Xingnan Zhou &middot; Concordia University, Montreal</p>
        <p style="margin-top: 8px; font-size: 0.9em;">
            &copy; 2026 | Built with the <a href="https://github.com/ss-zheng/Scenario-Dreamer" style="color: #4ECDC4;">Scenario Dreamer</a> framework
        </p>
    </div>
</body>
</html>