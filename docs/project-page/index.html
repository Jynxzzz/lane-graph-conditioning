<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Xingnan Zhou | Concordia University</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', sans-serif;
            line-height: 1.6;
            color: #333;
            background-color: #f5f6f8;
        }

        .header {
            background: linear-gradient(135deg, #0f1923 0%, #1a2940 50%, #243b55 100%);
            color: white;
            padding: 60px 20px 50px;
            text-align: center;
            position: relative;
            overflow: hidden;
        }

        .header::before {
            content: '';
            position: absolute;
            top: 0; left: 0; right: 0; bottom: 0;
            background: radial-gradient(ellipse at 30% 50%, rgba(78, 205, 196, 0.08) 0%, transparent 60%),
                        radial-gradient(ellipse at 70% 50%, rgba(69, 183, 209, 0.06) 0%, transparent 60%);
            pointer-events: none;
        }

        .header h1 { font-size: 2.6em; font-weight: 700; margin-bottom: 8px; position: relative; }
        .header .subtitle { font-size: 1.15em; opacity: 0.85; margin-top: 6px; position: relative; }
        .header .affiliation { font-size: 1.0em; opacity: 0.7; margin-top: 4px; position: relative; }

        .header-links {
            margin-top: 22px;
            display: flex;
            justify-content: center;
            gap: 14px;
            flex-wrap: wrap;
            position: relative;
        }

        .header-links a {
            display: inline-flex;
            align-items: center;
            gap: 6px;
            color: white;
            text-decoration: none;
            padding: 8px 18px;
            border: 1.5px solid rgba(255,255,255,0.35);
            border-radius: 6px;
            font-size: 0.93em;
            transition: all 0.2s ease;
        }

        .header-links a:hover {
            background: rgba(255,255,255,0.12);
            border-color: rgba(255,255,255,0.6);
        }

        .container { max-width: 920px; margin: 0 auto; padding: 36px 24px; }

        section {
            background: white;
            border-radius: 10px;
            padding: 32px 36px;
            margin-bottom: 24px;
            box-shadow: 0 1px 4px rgba(0,0,0,0.06);
        }

        h2 {
            font-size: 1.6em;
            color: #1a2940;
            margin-bottom: 18px;
            padding-bottom: 8px;
            border-bottom: 3px solid #4ECDC4;
        }

        p { margin-bottom: 12px; line-height: 1.75; }

        .about-content { display: flex; gap: 32px; align-items: flex-start; }
        .about-text { flex: 1; }

        .about-info {
            flex-shrink: 0;
            background: #f8f9fb;
            border-radius: 8px;
            padding: 20px 24px;
            font-size: 0.92em;
            min-width: 220px;
        }

        .about-info p { margin-bottom: 8px; line-height: 1.5; }
        .about-info strong { color: #1a2940; }

        .interests { display: flex; flex-wrap: wrap; gap: 8px; margin-top: 16px; }

        .interest-tag {
            background: #e8f7f6;
            color: #1a7a72;
            padding: 5px 14px;
            border-radius: 20px;
            font-size: 0.85em;
            font-weight: 500;
        }

        .pub-card {
            display: flex;
            gap: 24px;
            padding: 24px;
            background: #f8f9fb;
            border-radius: 10px;
            margin-bottom: 20px;
            border-left: 4px solid #4ECDC4;
            transition: box-shadow 0.2s ease;
        }

        .pub-card:hover { box-shadow: 0 4px 16px rgba(0,0,0,0.08); }

        .pub-thumb {
            flex-shrink: 0;
            width: 200px;
            height: 130px;
            border-radius: 6px;
            overflow: hidden;
            background: #e2e8f0;
        }

        .pub-thumb img { width: 100%; height: 100%; object-fit: cover; }
        .pub-info { flex: 1; }

        .pub-info h3 { font-size: 1.1em; color: #1a2940; margin-bottom: 6px; line-height: 1.4; }
        .pub-info h3 a { color: #1a2940; text-decoration: none; }
        .pub-info h3 a:hover { color: #2a8c85; }
        .pub-authors { font-size: 0.9em; color: #666; margin-bottom: 4px; }
        .pub-venue { font-size: 0.88em; color: #888; font-style: italic; margin-bottom: 8px; }
        .pub-desc { font-size: 0.9em; color: #555; margin-bottom: 10px; line-height: 1.6; }
        .pub-links { display: flex; gap: 10px; flex-wrap: wrap; }

        .pub-links a {
            display: inline-block;
            font-size: 0.82em;
            font-weight: 600;
            padding: 4px 12px;
            border-radius: 4px;
            text-decoration: none;
            transition: all 0.2s ease;
        }

        .pub-links .link-paper { background: #1a2940; color: white; }
        .pub-links .link-paper:hover { background: #243b55; }
        .pub-links .link-code { background: #e8f7f6; color: #1a7a72; }
        .pub-links .link-code:hover { background: #d0efed; }
        .pub-links .link-project { background: #fff3e0; color: #c08a20; }
        .pub-links .link-project:hover { background: #ffe8c0; }

        .badge {
            display: inline-block;
            padding: 2px 10px;
            border-radius: 12px;
            font-size: 0.75em;
            font-weight: 600;
            margin-left: 8px;
            vertical-align: middle;
        }

        .badge-review { background: #fff3e0; color: #e8a838; }
        .badge-published { background: #e8f5e9; color: #2e7d32; }

        .stats-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(180px, 1fr));
            gap: 14px;
            margin: 20px 0;
        }

        .stat-card { text-align: center; padding: 18px; background: #f8f9fb; border-radius: 8px; }
        .stat-card .number { font-size: 1.8em; font-weight: 700; color: #1a2940; }
        .stat-card .label { font-size: 0.85em; color: #888; margin-top: 2px; }

        .footer {
            background-color: #0f1923;
            color: white;
            text-align: center;
            padding: 28px 20px;
            margin-top: 16px;
        }

        .footer p { opacity: 0.7; text-align: center; font-size: 0.9em; }
        .footer a { color: #4ECDC4; text-decoration: none; }

        @media (max-width: 768px) {
            .header h1 { font-size: 1.8em; }
            section { padding: 24px 20px; }
            .about-content { flex-direction: column; }
            .about-info { min-width: unset; }
            .pub-card { flex-direction: column; }
            .pub-thumb { width: 100%; height: 160px; }
        }
    </style>
</head>
<body>

    <div class="header">
        <h1>Xingnan Zhou</h1>
        <div class="subtitle">Ph.D. Candidate &middot; Autonomous Driving &amp; Trajectory Prediction</div>
        <div class="affiliation">Department of Building, Civil and Environmental Engineering<br>Concordia University, Montreal, Canada</div>
        <div class="header-links">
            <a href="https://github.com/Jynxzzz">GitHub</a>
            <a href="mailto:zhouxingnan2016@gmail.com">Email</a>
            <a href="#publications">Publications</a>
        </div>
    </div>

    <div class="container">

        <section id="about">
            <h2>About</h2>
            <div class="about-content">
                <div class="about-text">
                    <p>
                        I am a Ph.D. candidate at <strong>Concordia University</strong> in Montreal,
                        working under the supervision of Prof. <strong>Ciprian Alecsandru</strong>.
                        My research focuses on trajectory prediction for autonomous driving,
                        with emphasis on incorporating structured road information (lane graphs)
                        to improve prediction accuracy and safety at urban intersections.
                    </p>
                    <p>
                        My work spans trajectory prediction with lane graph conditioning,
                        LiDAR-camera sensor fusion for occlusion-robust 3D detection,
                        and explainable AI for Transformer-based prediction models.
                        I am interested in making autonomous driving perception both more accurate and more interpretable.
                    </p>
                    <div class="interests">
                        <span class="interest-tag">Trajectory Prediction</span>
                        <span class="interest-tag">Lane Graph Reasoning</span>
                        <span class="interest-tag">Autonomous Driving</span>
                        <span class="interest-tag">3D Object Detection</span>
                        <span class="interest-tag">LiDAR-Camera Fusion</span>
                        <span class="interest-tag">Explainable AI</span>
                        <span class="interest-tag">Waymo Open Dataset</span>
                    </div>
                </div>
                <div class="about-info">
                    <p><strong>Affiliation</strong><br>Concordia University</p>
                    <p><strong>Supervisor</strong><br>Prof. Ciprian Alecsandru</p>
                    <p><strong>Email</strong><br>zhouxingnan2016@gmail.com</p>
                    <p><strong>Location</strong><br>Montreal, QC, Canada</p>
                </div>
            </div>
        </section>

        <section id="publications">
            <h2>Publications</h2>

            <div class="pub-card">
                <div class="pub-thumb">
                    <img src="assets/anim_scene_1_left_turn.gif" alt="Lane-conditioned prediction demo">
                </div>
                <div class="pub-info">
                    <h3>
                        <a href="lane-conditioning.html">Local Lane Graph Conditioning as a General Inductive Bias for Trajectory Prediction: A Multi-Architecture Study on the Waymo Open Motion Dataset</a>
                        <span class="badge badge-review">Under Review</span>
                    </h3>
                    <div class="pub-authors"><strong>Xingnan Zhou</strong>, Ciprian Alecsandru</div>
                    <div class="pub-venue">Submitted to MDPI Sustainability, February 2026</div>
                    <div class="pub-desc">
                        A waterflow lane graph extraction method with cross-attention fusion that achieves
                        <strong>+27.3% minADE</strong> and <strong>+42.7% miss rate</strong> improvement
                        on 89K Waymo intersection scenarios. Architecture-agnostic across LSTM and Transformer backbones.
                    </div>
                    <div class="pub-links">
                        <a href="assets/lane-conditioning-paper.pdf" class="link-paper">PDF</a>
                        <a href="https://github.com/Jynxzzz/scenario-dreamer-jynxzzz" class="link-code">Code</a>
                        <a href="lane-conditioning.html" class="link-project">Project Page</a>
                    </div>
                </div>
            </div>

            <div class="pub-card">
                <div class="pub-thumb" style="display: flex; align-items: center; justify-content: center; background: linear-gradient(135deg, #e3f2fd, #bbdefb);">
                    <span style="font-size: 2.8em;">&#128752;</span>
                </div>
                <div class="pub-info">
                    <h3>
                        <a href="turn-aware-lstm.html">Turn-Aware LSTM Model for Vehicle Trajectory Forecasting</a>
                        <span class="badge badge-published">Published</span>
                    </h3>
                    <div class="pub-authors"><strong>Xingnan Zhou</strong>, Ciprian Alecsandru, Shahram Bashbaghi, Yongjun Jeong, Yuche Chen</div>
                    <div class="pub-venue">Advances in Transportation Studies (ATS), 2025</div>
                    <div class="pub-desc">
                        A Turn-Aware LSTM that encodes cumulative heading changes and one-hot maneuver indicators
                        for intersection trajectory prediction. Reduces FDE by <strong>15&ndash;20%</strong> for turning maneuvers
                        vs. vanilla LSTM, with real-time inference (~2.5 ms) on UAV-captured intersection data in Montreal.
                    </div>
                    <div class="pub-links">
                        <a href="assets/ATS2025_069_R1_Final_Xingnan_Zhou.pdf" class="link-paper">PDF</a>
                        <a href="https://github.com/Jynxzzz/Turn-Aware-LSTM_SUPP" class="link-code">Code &amp; Data</a>
                        <a href="turn-aware-lstm.html" class="link-project">Project Page</a>
                    </div>
                </div>
            </div>

            <div class="pub-card">
                <div class="pub-thumb" style="display: flex; align-items: center; justify-content: center; background: linear-gradient(135deg, #fce4ec, #f8bbd0);">
                    <span style="font-size: 2.8em;">&#128065;</span>
                </div>
                <div class="pub-info">
                    <h3>
                        <a href="attention-visualization.html">Spatial Attention Visualization for Interpretable Trajectory Prediction in Autonomous Driving: Discovering Safety Blind Spots Through Counterfactual Analysis</a>
                        <span class="badge badge-review">In Preparation</span>
                    </h3>
                    <div class="pub-authors"><strong>Xingnan Zhou</strong>, Ciprian Alecsandru</div>
                    <div class="pub-venue">Submitted to MDPI Sustainability, 2026</div>
                    <div class="pub-desc">
                        A spatial attention visualization framework for Transformer-based trajectory prediction.
                        Discovers that VRUs receive up to <strong>60% less attention</strong> than vehicles &mdash;
                        a safety blind spot. Introduces counterfactual attention analysis on the Waymo dataset (MTR-Lite, 8.48M params).
                    </div>
                    <div class="pub-links">
                        <a href="assets/attention-visualization-paper.pdf" class="link-paper">PDF</a>
                        <a href="attention-visualization.html" class="link-project">Project Page</a>
                    </div>
                </div>
            </div>

            <div class="pub-card">
                <div class="pub-thumb">
                    <img src="assets/bev_lidar/fig_pipeline.png" alt="Dual-camera LiDAR fusion pipeline">
                </div>
                <div class="pub-info">
                    <h3>
                        <a href="bev-lidar-fusion.html">Dual-Camera LiDAR Fusion for Occlusion-Robust 3D Detection in Urban Driving Simulation</a>
                        <span class="badge badge-review">In Preparation</span>
                    </h3>
                    <div class="pub-authors"><strong>Xingnan Zhou</strong>, Ciprian Alecsandru</div>
                    <div class="pub-venue">Submitted to MDPI Sustainability, 2026</div>
                    <div class="pub-desc">
                        An asymmetric dual-camera LiDAR fusion framework combining PointPillars with drone and forward-camera
                        YOLOv8 detections. Achieves <strong>+11.2% mAP@0.5</strong> improvement (sign test p&nbsp;=&nbsp;0.031)
                        on a CARLA Town10HD dataset with 5-seed validation.
                    </div>
                    <div class="pub-links">
                        <a href="assets/bev-lidar-fusion-paper.pdf" class="link-paper">PDF</a>
                        <a href="bev-lidar-fusion.html" class="link-project">Project Page</a>
                    </div>
                </div>
            </div>

        </section>

        <section id="highlights">
            <h2>Research Highlights</h2>
            <div class="stats-grid">
                <div class="stat-card">
                    <div class="number">4</div>
                    <div class="label">Papers (1 Published)</div>
                </div>
                <div class="stat-card">
                    <div class="number">89K</div>
                    <div class="label">Waymo Scenarios</div>
                </div>
                <div class="stat-card">
                    <div class="number">27.3%</div>
                    <div class="label">minADE Improvement</div>
                </div>
                <div class="stat-card">
                    <div class="number">+11.2%</div>
                    <div class="label">mAP@0.5 Fusion Gain</div>
                </div>
            </div>
            <p style="text-align: center; color: #888; font-size: 0.9em;">
                Spanning trajectory prediction, 3D perception, and explainable AI &mdash;
                see individual <a href="#publications" style="color: #2a8c85;">project pages</a> for details.
            </p>
        </section>

    </div>

    <div class="footer">
        <p>Xingnan Zhou &middot; Concordia University, Montreal &middot; <a href="https://github.com/Jynxzzz">GitHub</a></p>
        <p style="margin-top: 6px;">&copy; 2026</p>
    </div>

</body>
</html>
